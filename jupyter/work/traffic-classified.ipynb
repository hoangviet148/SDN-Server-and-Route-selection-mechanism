{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d6bb8a-656b-4e53-b880-51c0906fa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time, localtime\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import numpy as np\n",
    "# from utils import plot_graph\n",
    "# import tensorflow_federated as tff\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import losses, metrics, optimizers\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "from pathlib import Path\n",
    "# from tensorflow_federated.python.research.utils import checkpoint_manager\n",
    "# import tensorflow_addons as tfa\n",
    "nest_asyncio.apply()\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b76820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key=List.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df353d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       flow_id    0    1    2    3    4    5    6    7    8    9  Label\n",
      "0           29   16   10  149  182  192  172  158  109   13   79      1\n",
      "1           29   16   10  168  155  186  253  154  217  174   83      1\n",
      "2           29   16   10  167  101   83  237  126   84  226   69      1\n",
      "3           29   16   10  166  230  173   64    4  169   36  232      1\n",
      "4           29   16   10  165   59   89  192  140  124  161  173      1\n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...\n",
      "55595   138365  144  111   86  255  137  119   88  101  151   95      2\n",
      "55596   138365  144  239   86  254  137  119   84  165  151   95      2\n",
      "55597   138365  144  111   87   16  137  119  152   37  151   95      2\n",
      "55598   138365  144  111   87    6  137  119  114  165  151   95      2\n",
      "55599   138365  144  111   87   17  137  119  155  229  151   95      2\n",
      "\n",
      "[55600 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"/home/jovyan/dataset/GQUIC_small/Test/GQUIC_test_10.feather\"\n",
    "test = pd.read_feather(test_dir)\n",
    "print(test)\n",
    "test.to_csv(\"/home/jovyan/dataset/GQUIC_small/Test/GQUIC_test_10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe50e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test.groupby('flow_id')['Label'].apply(list).to_dict()\n",
    "# print(result, type(result))\n",
    "flow_label = []\n",
    "for flow in result:\n",
    "    flow_label.append(most_frequent(result[flow]))\n",
    "\n",
    "flow_label = np.array(flow_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5805a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test = test.drop('flow_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb55b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_test = true_test.drop('Label', axis=1).to_numpy()/255\n",
    "print(type(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "903b6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1,20,512,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef04138",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "921240ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"/home/jovyan/dataset/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369418a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cca576",
   "metadata": {},
   "source": [
    "#### Predict all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55e77824",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 128, 1), found shape=(None, 20, 512, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_test,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file78bvca1w.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 20, 128, 1), found shape=(None, 20, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test,verbose=2,use_multiprocessing=True,batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
